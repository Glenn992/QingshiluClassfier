# services/analysis_service.py
# ----------------------------------------------------
# QingShiluService ç±»ï¼šæ ¸å¿ƒåˆ†æç®—æ³•ã€ä¸šåŠ¡é€»è¾‘

import re

# ä»åŒçº§æ¨¡å—å¯¼å…¥ DataModel
from gemini.services.data_model import DataModel


class QingShiluService:
    """
    è´Ÿè´£æ‰§è¡Œæ ¸å¿ƒåˆ†æç®—æ³•å’Œç®¡ç†æ•°æ®æ“ä½œã€‚
    """

    def __init__(self):
        self.model = DataModel()

    # --- æ ¸å¿ƒåˆ†ææ–¹æ³• (JS: translateAndRecommend) ---

    def run_full_analysis(self, original_text: str):
        """
        æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½åˆ†ææµç¨‹ï¼ˆè€—æ—¶æ“ä½œï¼Œéœ€ç”± WorkerThread è°ƒç”¨ï¼‰ã€‚
        """
        # æ¨¡æ‹Ÿ BERT/NLP æ¨¡å‹çš„æ¨ç†æ—¶é—´ (JS æ¨¡æ‹Ÿçš„å¼‚æ­¥è€—æ—¶)
        # ğŸŒŸ ç§»é™¤æˆ–æ³¨é‡Šæ‰ time.sleep(1.5)
        # time.sleep(1.5)

        core_info = self._extract_core_info(original_text)

        # ğŸŒŸ è°ƒç”¨ç°åœ¨ä½äºæ­¤ç±»çš„å†…éƒ¨
        keywords = self._extract_keywords(original_text)

        translation = self._simulate_optimized_translation(original_text, core_info)

        recommendations = self._get_classification_recommendations(original_text, keywords)
        similar_texts = self._find_similar_texts(original_text)

        return {
            'translation': translation,
            'core_info': core_info,
            'keywords': keywords,
            'recommendations': recommendations,
            'similar_texts': similar_texts,
            'category_structure': self.model.categoryStructure  # å°†ç»“æ„ä¹Ÿè¿”å›ç»™ Controller
        }

    # --- å†…éƒ¨è¾…åŠ©æ–¹æ³• (JS æ ¸å¿ƒé€»è¾‘çš„ Python ç¿»è¯‘) ---

    def _extract_core_info(self, text):
        """æå–æ ¸å¿ƒä¿¡æ¯ï¼ˆJS: extractCoreInfoï¼‰"""
        # ... (æ‚¨åŸæœ‰çš„ _extract_core_info å®Œæ•´å†…å®¹) ...
        # æå–ä¸»ä½“
        subject = ""
        # åŒ¹é… JS å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼
        subject_matches = re.search(r"(â—‹\d+)?\s*(\w+?å·¡æŠš|\w+?æ€»ç£|\w+?æŒ‰å¯Ÿä½¿|\w+?çŸ¥åºœ|\w+?çŸ¥å¿|çš‡ä¸Š|çš‡å¸|æœå»·|éƒ¨è®®)",
                                    text)
        if subject_matches:
            # Python re.search è¿”å› groups
            subject = subject_matches.group(2) if subject_matches.group(2) else subject_matches.group(1)

        # æå–æ ¸å¿ƒåŠ¨ä½œ
        action = ""
        action_keywords = ["å‚å¥", "é¢˜å‚", "ç–æŠ¥", "è°•ä»¤", "è°•", "æŠšæ¤", "èµˆæµ", "å‰¿", "æ•", "å®¡", "åˆ¤", "ä»»å…", "è°ƒ",
                           "é©èŒ"]
        for keyword in action_keywords:
            if keyword in text:
                action = keyword
                break

        # æå–äº‹ä»¶æ€§è´¨ (åŸºäºå…³é”®å­—çš„ç®€å•åˆ¤æ–­)
        nature = ""
        if "ä¸æ•ˆåŠ›" in text or "å¾‡ç§" in text or "è´ªæš´" in text or "å¤±èŒ" in text:
            nature = "å®˜å‘˜å¤±èŒé—®é¢˜"
        elif "è¢«ç¾" in text or "æŠšæ¤" in text or "èµˆæµ" in text:
            nature = "ç¾å®³æ•‘æµäº‹åŠ¡"
        # ... (çœç•¥å…¶ä»–æ€§è´¨åˆ¤æ–­)

        return {"subject": subject, "action": action, "nature": nature}

    def _simulate_optimized_translation(self, original_text, core_info):
        """ä¼˜åŒ–çš„ç¿»è¯‘ï¼ˆJS: simulateOptimizedTranslationï¼‰"""
        # ... (æ‚¨åŸæœ‰çš„ _simulate_optimized_translation å®Œæ•´å†…å®¹) ...
        translation = f"ã€æ ¸å¿ƒä¿¡æ¯ã€‘ä¸»ä½“: {core_info.get('subject', 'æ— ')}, æ€§è´¨: {core_info.get('nature', 'æ— ')}\n\n"
        translation += "è¿™æ˜¯ Service å±‚å¯¹åŸæ–‡çš„ç™½è¯æ–‡ç¿»è¯‘ã€‚\n\n"

        # æ·»åŠ æœ¯è¯­æ³¨é‡Š
        terms = {
            "é¢˜å‚": "ä¸Šå¥å‚åŠ¾",
            "è ²å…": "å…é™¤èµ‹ç¨",
            "èµˆç²œ": "å¹³ä»·å–ç²®æ•‘ç¾",
            "å¹³ç²œ": "å¹³ä»·å–ç²®",
        }

        for term, note in terms.items():
            if term in original_text:
                translation += f"ã€æœ¯è¯­æ³¨é‡Šã€‘'{term}' æ„ä¸º '{note}'ã€‚\n"

        return translation

    # ğŸŒŸ ã€å…³é”®ä¿®å¤ã€‘æ­£ç¡®çš„ä½ç½®ï¼Œåœ¨ä¸» QingShiluService ç±»å†…éƒ¨
    def _extract_keywords(self, text):
        """æå–å…³é”®è¯ï¼ˆJS: extractKeywordsï¼‰"""
        all_keywords = set()

        # ç¡®ä¿æ‰€æœ‰ç©ºæ ¼ã€æ¢è¡Œç¬¦è¢«æ¸…ç† (ç”Ÿäº§ä»£ç ç‰ˆæœ¬)
        clean_text = text.replace('\n', '').replace('\r', '').strip()

        # ä»åˆå¹¶çš„è¯åº“ä¸­æå–å…³é”®è¯
        for category, data in self.model.mergedKeywordMap.items():
            keywords = data['keywords']
            for keyword in keywords:
                # åŒ¹é…é€»è¾‘ä¿æŒä¸å˜
                if keyword in clean_text:
                    all_keywords.add(keyword)

        return list(all_keywords)

    def _get_classification_recommendations(self, text, keywords):
        """è·å–åˆ†ç±»æ¨èï¼ˆJS: getClassificationRecommendationsï¼‰"""
        # ... (æ‚¨åŸæœ‰çš„ _get_classification_recommendations å®Œæ•´å†…å®¹) ...
        recommendations = []
        category_scores = {}

        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„åŒ¹é…åˆ†æ•°
        for category, data in self.model.mergedKeywordMap.items():
            category_keywords = data['keywords']
            score = 0

            for keyword in keywords:
                if keyword in category_keywords:
                    score += 1

            if score > 0:
                category_scores[category] = score

        # æ’åºå¹¶è¿”å›å‰3ä¸ªæ¨è
        sorted_categories = sorted(category_scores.items(), key=lambda item: item[1], reverse=True)[:3]

        for category, score in sorted_categories:
            parts = category.split('-')
            level1 = parts[0]
            level2 = parts[1]
            level3 = parts[2]

            recommendations.append({
                "category": category,
                "level1": level1,
                "level2": level2,
                "level3": level3,
                "score": score,
                "reason": self.model.mergedKeywordMap[category].get('description', 'æ— '),
                "matchedKeywords": [kw for kw in keywords if kw in self.model.mergedKeywordMap[category]['keywords']]
            })

        return recommendations

    def _find_similar_texts(self, text):
        """æŸ¥æ‰¾ç›¸ä¼¼æ–‡æœ¬ï¼ˆJS: findSimilarTextsï¼‰"""
        # ... (æ‚¨åŸæœ‰çš„ _find_similar_texts å®Œæ•´å†…å®¹) ...
        all_texts = []

        # æ”¶é›†æ‰€æœ‰å·²åˆ†ç±»çš„æ–‡æœ¬
        for l1, v1 in self.model.classifiedData.items():
            for l2, v2 in v1.items():
                for l3, texts in v2.items():
                    for t in texts:
                        all_texts.append({
                            **t,
                            "categoryPath": f"{l1}é›† â†’ {l2} â†’ {l3}"
                        })

        similar_texts = []
        text_keywords = self._extract_keywords(text)  # æ³¨æ„ï¼šè¿™é‡Œä¼šé€’å½’è°ƒç”¨ _extract_keywords

        for stored_text in all_texts:
            stored_keywords = self._extract_keywords(stored_text['originalText'])
            common_keywords = [kw for kw in text_keywords if kw in stored_keywords]

            if len(common_keywords) >= 2:
                similar_texts.append({
                    **stored_text,
                    "similarity": len(common_keywords),
                    "commonKeywords": common_keywords
                })

        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè¿”å›å‰3ä¸ª
        return sorted(similar_texts, key=lambda x: x['similarity'], reverse=True)[:3]

    # --- æ•°æ®ç®¡ç†æ–¹æ³• (è°ƒç”¨ DataModel) ---

    def save_classification_result(self, original_text, translation, classification_key,
                                   article_id: str | None = None):
        """ä¿å­˜å•æ¡åˆ†ç±»ç»“æœï¼Œæ–°å¢ article_id å‚æ•°"""
        self.model.save_classified_text(original_text, translation, classification_key, article_id)

    # --- å…³é”®è¯å’Œåˆ†ç±»ç®¡ç†æ–¹æ³• ---

    def get_all_categories_map(self):
        """è·å–æ‰€æœ‰åˆ†ç±»é”®å€¼å’Œæè¿°çš„æ‰å¹³åŒ–æ˜ å°„"""
        return self.model.mergedKeywordMap

    def get_keywords_for_category(self, category_key):
        """è·å–æŒ‡å®šåˆ†ç±»çš„å…³é”®è¯åˆ—è¡¨"""
        return self.model.mergedKeywordMap.get(category_key, {}).get('keywords', [])

    def save_keywords(self, category_key, keywords):
        """ä¿å­˜å…³é”®è¯å¹¶æ›´æ–°æ¨¡å‹"""
        self.model.update_custom_keywords(category_key, keywords)

    def get_category_structure(self):
        """è·å–ä¸‰çº§åˆ†ç±»ç»“æ„"""
        return self.model.categoryStructure